//
//  StickerViewModel.swift
//  Test
//
//  Created by è´¾å»ºè¾‰ on 2025/10/5.
//

import SwiftUI
import PhotosUI
import Vision
import CoreImage

// MARK: - å¤„ç†çŠ¶æ€æšä¸¾ï¼ˆçŠ¶æ€æœºï¼‰
enum ProcessingState {
    case initial      // åˆå§‹çŠ¶æ€
    case analyzing    // è¯†åˆ«ä¸­ï¼ˆå…¨å±æ˜¾ç¤ºåŸå›¾ï¼‰
    case extracting   // ä¸»ä½“è·³å‡ºåŠ¨ç”»
    case completed    // å®Œæˆï¼ˆæ˜¾ç¤ºå¡ç‰‡ï¼‰
}


// MARK: - vm

@MainActor
class StickerViewModel: ObservableObject {
    // ===== çŠ¶æ€ç®¡ç† =====
    @Published var currentState: ProcessingState = .initial
    
    // ===== æ•°æ®ï¼Œé€‰æ‹©çš„å›¾ç‰‡ã€è¯†åˆ«çš„ä¸»ä½“å›¾ç‰‡ï¼ˆå¸¦ç™½è‰²æè¾¹ï¼‰ =====
    @Published var capturedImage: UIImage?
    @Published var extractedSubject: UIImage?
    @Published var dominantColor: Color = .blue

    
    // ===== UI å¼¹çª—æ§åˆ¶ =====
    @Published var showPhotoPicker = false
    @Published var showSaveAlert = false
    
    // ===== è®¡ç®—å±æ€§ï¼Œå½“é€‰æ‹©ä¸€ä¸ªå›¾ç‰‡åï¼Œè‡ªåŠ¨è°ƒç”¨å‡½æ•° loadPhoto =====
    @Published var selectedPhoto: PhotosPickerItem? {
        didSet {
            if selectedPhoto != nil {
                loadPhoto()
            }
        }
    }
    
    // ===== æµç¨‹1: åŠ è½½ç…§ç‰‡ =====
    private func loadPhoto() {
        
        // ç”¨æˆ·æ²¡æœ‰é€‰æ‹©å›¾ç‰‡ï¼Œç›´æ¥è¿”å›
        guard let item = selectedPhoto else { return }
        
        
        // å¼‚æ­¥æ–¹å¼åŠ è½½å›¾ç‰‡
        Task {
            do {
                
                // è·å–å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®ï¼›
                guard let data = try await item.loadTransferable(type: Data.self),
                      // æŠŠäºŒè¿›åˆ¶æ•°æ®è½¬æ¢æˆå›¾ç‰‡
                      let image = UIImage(data: data)
                else { return }
                
                // ä¿®æ­£å›¾ç‰‡æ–¹å‘
                let fixedImage = image.fixedOrientation()
                capturedImage = fixedImage
                
                // ã€åŠ¨ç”»é˜¶æ®µ1ã€‘åˆ‡æ¢åˆ°è¯†åˆ«çŠ¶æ€
                withAnimation(.easeIn(duration: 0.3)) {
                    currentState = .analyzing
                }
                
                // å¼€å§‹è¯†åˆ«ï¼ˆæ¨¡æ‹Ÿå»¶è¿Ÿä»¥å±•ç¤ºåŠ¨ç”»ï¼‰
                try await Task.sleep(nanoseconds: 1_000_000_000) // 1.0ç§’
                
                // æ‰§è¡Œå®é™…è¯†åˆ«
                await performExtraction(fixedImage)
                
            } catch {
                print("âŒ é”™è¯¯: \(error)")
            }
        }
    }
    
    // ===== æµç¨‹2: æ‰§è¡Œæå– =====
    private func performExtraction(_ image: UIImage) async {
        // Vision æå–ä¸»ä½“
        guard let extracted = await extractSubject(from: image) else {
            reset()
            return
        }
        
        // ğŸ†• è£å‰ªåˆ°ä¸»ä½“è¾¹ç•Œ
        let cropped = cropToSubject(extracted) ?? extracted
        
        // æ·»åŠ ç™½è¾¹
        let withBorder = addWhiteBorder(to: cropped, borderWidth: 16)
        extractedSubject = withBorder
        
        // ã€åŠ¨ç”»é˜¶æ®µ2ã€‘åˆ‡æ¢åˆ°è·³å‡ºåŠ¨ç”»
        withAnimation(.easeOut(duration: 0.3)) {
            currentState = .extracting
        }
        
        // ğŸ¨ æå–ä¸»è‰²
        dominantColor = extractRefinedColor(from: cropped)

        
        // ç­‰å¾…è·³å‡ºåŠ¨ç”»å®Œæˆ
        try? await Task.sleep(nanoseconds: 1_600_000_000) // 1.6ç§’
        
        // ã€åŠ¨ç”»é˜¶æ®µ3ã€‘åˆ‡æ¢åˆ°å®ŒæˆçŠ¶æ€
        withAnimation(.spring(response: 0.6, dampingFraction: 0.8)) {
            currentState = .completed
        }
    }
    
    // ===== Vision AI æå–ä¸»ä½“ =====
    private func extractSubject(from image: UIImage) async -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        
        do {
            let request = VNGenerateForegroundInstanceMaskRequest()
            let handler = VNImageRequestHandler(cgImage: cgImage)
            try handler.perform([request])
            
            guard let result = request.results?.first else { return nil }
            
            let mask = try result.generateScaledMaskForImage(
                forInstances: result.allInstances,
                from: handler
            )
            
            return applyMask(mask, to: image)
            
        } catch {
            print("âŒ Vision é”™è¯¯: \(error)")
            return nil
        }
    }
    
    
    // ===== è£å‰ªåˆ°ä¸»ä½“è¾¹ç•Œ =====
    private func cropToSubject(_ image: UIImage) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }

        let scaleFactor: CGFloat = 0.2 // é™ä½åˆ†è¾¨ç‡åˆ°20%
        let width = Int(CGFloat(cgImage.width) * scaleFactor)
        let height = Int(CGFloat(cgImage.height) * scaleFactor)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else { return nil }

        context.interpolationQuality = .low
        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))

        guard let data = context.data else { return nil }
        let buffer = data.bindMemory(to: UInt8.self, capacity: width * height * 4)

        var minX = width, maxX = 0
        var minY = height, maxY = 0

        for y in 0..<height {
            for x in 0..<width {
                let alpha = buffer[(y * width + x) * 4 + 3]
                if alpha > 10 {
                    minX = min(minX, x)
                    maxX = max(maxX, x)
                    minY = min(minY, y)
                    maxY = max(maxY, y)
                }
            }
        }

        guard maxX > minX, maxY > minY else { return nil }

        // è½¬æ¢å›åŸå§‹åæ ‡
        let factorX = CGFloat(cgImage.width) / CGFloat(width)
        let factorY = CGFloat(cgImage.height) / CGFloat(height)
        let cropRect = CGRect(
            x: CGFloat(minX) * factorX,
            y: CGFloat(minY) * factorY,
            width: CGFloat(maxX - minX + 1) * factorX,
            height: CGFloat(maxY - minY + 1) * factorY
        )

        guard let croppedCG = cgImage.cropping(to: cropRect) else { return nil }
        let croppedImage = UIImage(cgImage: croppedCG, scale: image.scale, orientation: image.imageOrientation)

        return resizeToSquare(croppedImage, targetSize: 800)
    }


    // ğŸ†• ç¼©æ”¾åˆ°æ­£æ–¹å½¢ç”»å¸ƒï¼ˆä¿æŒä¸»ä½“å±…ä¸­ï¼‰
    private func resizeToSquare(_ image: UIImage, targetSize: CGFloat) -> UIImage {
        let size = image.size
        let aspectRatio = size.width / size.height
        
        // è®¡ç®—ä¸»ä½“å°ºå¯¸ï¼ˆå ç”»å¸ƒçš„80%ï¼‰
        let contentRatio: CGFloat = 0.8
        let contentSize = targetSize * contentRatio
        
        var drawSize: CGSize
        if aspectRatio > 1 {
            // æ¨ªå‘å›¾
            drawSize = CGSize(width: contentSize, height: contentSize / aspectRatio)
        } else {
            // çºµå‘å›¾
            drawSize = CGSize(width: contentSize * aspectRatio, height: contentSize)
        }
        
        // è®¡ç®—å±…ä¸­ä½ç½®
        let x = (targetSize - drawSize.width) / 2
        let y = (targetSize - drawSize.height) / 2
        
        // ä½¿ç”¨é«˜è´¨é‡æ¸²æŸ“
        let format = UIGraphicsImageRendererFormat()
        format.scale = 2.0 // ğŸ¯ 3x åˆ†è¾¨ç‡ï¼ˆæ¸…æ™°ï¼‰
        format.opaque = false
        
        let renderer = UIGraphicsImageRenderer(size: CGSize(width: targetSize, height: targetSize), format: format)
        
        return renderer.image { context in
            // é«˜è´¨é‡æ’å€¼
            context.cgContext.interpolationQuality = .medium
            
            // é€æ˜èƒŒæ™¯
            UIColor.clear.setFill()
            context.fill(CGRect(origin: .zero, size: CGSize(width: targetSize, height: targetSize)))
            
            // ç»˜åˆ¶å›¾ç‰‡
            image.draw(in: CGRect(x: x, y: y, width: drawSize.width, height: drawSize.height))
        }
    }
    
    // ===== åº”ç”¨è’™ç‰ˆ =====
    private func applyMask(_ mask: CVPixelBuffer, to image: UIImage) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        
        let ciImage = CIImage(cgImage: cgImage)
        let maskCIImage = CIImage(cvPixelBuffer: mask)
        
        let scaleX = ciImage.extent.width / maskCIImage.extent.width
        let scaleY = ciImage.extent.height / maskCIImage.extent.height
        let scaledMask = maskCIImage.transformed(by: CGAffineTransform(scaleX: scaleX, y: scaleY))
        
        guard let filter = CIFilter(name: "CIBlendWithMask") else { return nil }
        filter.setValue(ciImage, forKey: kCIInputImageKey)
        filter.setValue(scaledMask, forKey: kCIInputMaskImageKey)
        filter.setValue(CIImage.empty(), forKey: kCIInputBackgroundImageKey)
        
        guard let output = filter.outputImage else { return nil }
        
        let context = CIContext()
        guard let cgOutput = context.createCGImage(output, from: output.extent) else { return nil }
        
        return UIImage(cgImage: cgOutput)
    }
    
    
    // ===== æ·»åŠ ç™½è‰²æè¾¹ï¼ˆå›ºå®šåƒç´ å®½åº¦ï¼‰ =====
    private func addWhiteBorder(to image: UIImage, borderWidth: CGFloat) -> UIImage {
        let scale: CGFloat = 3.0 // åŒ¹é…ä¸Šé¢çš„scale
        let size = image.size
        
        let format = UIGraphicsImageRendererFormat()
        format.scale = scale
        format.opaque = false
        
        let renderer = UIGraphicsImageRenderer(size: size, format: format)
        
        return renderer.image { context in
            let ctx = context.cgContext
            
            // é«˜è´¨é‡æ¸²æŸ“
            ctx.interpolationQuality = .high
            ctx.setShouldAntialias(true)
            
            let rect = CGRect(origin: .zero, size: size)
            
            // 1. ç»˜åˆ¶ç™½è‰²æè¾¹å±‚
            let offset = borderWidth
            let directions: [(CGFloat, CGFloat)] = [
                (-offset, -offset), (0, -offset), (offset, -offset),
                (-offset, 0),                      (offset, 0),
                (-offset, offset),  (0, offset),  (offset, offset)
            ]
            
            for (dx, dy) in directions {
                ctx.saveGState()
                ctx.translateBy(x: dx, y: dy)
                
                // ç»˜åˆ¶å›¾ç‰‡
                image.draw(in: rect)
                
                // ç”¨ç™½è‰²å¡«å……
                ctx.setBlendMode(.sourceIn)
                ctx.setFillColor(UIColor.white.cgColor)
                ctx.fill(rect)
                ctx.setBlendMode(.normal)
                
                ctx.restoreGState()
            }
            
            // 2. ç»˜åˆ¶åŸå›¾
            image.draw(in: rect)
        }
    }
    

    
    // ===== ä¿å­˜ =====
    func saveSticker() {
        guard let image = extractedSubject else { return }
        UIImageWriteToSavedPhotosAlbum(image, nil, nil, nil)
        showSaveAlert = true
    }
    
    // ===== é‡ç½® =====
    func reset() {
        withAnimation(.easeOut(duration: 0.3)) {
            currentState = .initial
        }
        capturedImage = nil
        extractedSubject = nil
        selectedPhoto = nil
    }
}


/**
 ä»å›¾ç‰‡ä¸­æå–å¹³å‡è‰²ï¼Œå¹¶è°ƒæ•´é¥±å’Œåº¦å’Œäº®åº¦ï¼Œç”Ÿæˆâ€œé«˜çº§â€èƒŒæ™¯è‰²ã€‚

 @param image è¦å¤„ç†çš„ UIImageã€‚
 @param saturationFactor é¥±å’Œåº¦ä¹˜æ•° (0.0 - 1.0)ã€‚ä¾‹å¦‚ï¼Œ0.3 ä¼šä½¿é¢œè‰²æ›´â€œç°â€ã€‚
 @param brightnessFactor äº®åº¦ä¹˜æ•° (0.0 - 1.0)ã€‚ä¾‹å¦‚ï¼Œ0.9 ä¼šä½¿é¢œè‰²æ›´â€œäº®â€ã€‚
 @return è°ƒæ•´åçš„ SwiftUI Colorã€‚
 */
private func extractRefinedColor(from image: UIImage,
                                 saturation: CGFloat = 0.3,
                                 brightness: CGFloat = 0.95) -> Color {
    
    // --- ç¬¬ 1 æ­¥ï¼šæå–å¹³å‡è‰² (ä½¿ç”¨ UIGraphicsImageRenderer æ›´ç®€æ´) ---
    let size = CGSize(width: 1, height: 1)
    let renderer = UIGraphicsImageRenderer(size: size)
    
    let uiColor = renderer.image { context in
        image.draw(in: CGRect(origin: .zero, size: size))
    }.averageColor // ä½¿ç”¨ UIImage çš„ averageColor æ‰©å±•ï¼ˆè§ä¸‹æ–¹ï¼‰
    
    guard let baseColor = uiColor else { return .gray }

    // --- ç¬¬ 2 æ­¥ï¼šè½¬æ¢ä¸º HSB å¹¶è°ƒæ•´ ---
    var hue: CGFloat = 0
    var currentSaturation: CGFloat = 0
    var currentBrightness: CGFloat = 0
    var alpha: CGFloat = 0

    // å°† UIColor è½¬æ¢ä¸º HSB ç©ºé—´
    baseColor.getHue(&hue, saturation: &currentSaturation, brightness: &currentBrightness, alpha: &alpha)

    // --- ç¬¬ 3 æ­¥ï¼šåº”ç”¨è‡ªå®šä¹‰é¥±å’Œåº¦å’Œäº®åº¦ ---
    
    // å¼ºåˆ¶ä½¿ç”¨è‡ªå®šä¹‰é¥±å’Œåº¦å’Œäº®åº¦ã€‚
    // ä¾‹å¦‚ï¼Œæ‚¨çš„è“è‰²ç“¶å­é¢œè‰² (ä½é¥±å’Œåº¦ã€é«˜äº®åº¦) å˜ä¸ºï¼š
    // æ–°çš„é¥±å’Œåº¦ = 0.3 (å˜ç°)
    // æ–°çš„äº®åº¦   = 0.9 (å˜äº®)
    let newSaturation = min(currentSaturation * saturation, 1.0)
    let newBrightness = min(brightness, 1.0) // ç›´æ¥ä½¿ç”¨æ‚¨æƒ³è¦çš„é«˜äº®åº¦å€¼

    // --- ç¬¬ 4 æ­¥ï¼šåˆ›å»ºæ–°çš„ UIColor ---
    let finalUIColor = UIColor(hue: hue, saturation: newSaturation, brightness: newBrightness, alpha: 1.0)

    // --- ç¬¬ 5 æ­¥ï¼šè¿”å› SwiftUI Color ---
    return Color(finalUIColor)
}


// è¾…åŠ©æ‰©å±•ï¼šè·å– UIImage çš„å¹³å‡è‰²ï¼ˆåŸºäº Core Image æˆ– UIGraphicsï¼‰
// ä¸ºäº†ä»£ç å®Œæ•´æ€§ï¼Œè¿™é‡Œä½¿ç”¨æˆ‘ç¬¬ä¸€ä¸ªå›ç­”ä¸­ä»‹ç»çš„ Core Image æ–¹æ³•
extension UIImage {
    var averageColor: UIColor? {
        guard let ciImage = CIImage(image: self) else { return nil }
        let extentVector = CIVector(cgRect: ciImage.extent)
        guard let filter = CIFilter(name: "CIAreaAverage", parameters: [kCIInputImageKey: ciImage, kCIInputExtentKey: extentVector]) else { return nil }
        guard let outputImage = filter.outputImage else { return nil }
        
        let context = CIContext(options: [.workingColorSpace: NSNull()])
        var bitmap = [UInt8](repeating: 0, count: 4)
        
        context.render(outputImage,
                       toBitmap: &bitmap,
                       rowBytes: 4,
                       bounds: CGRect(x: 0, y: 0, width: 1, height: 1),
                       format: .RGBA8,
                       colorSpace: nil)
        
        let r = CGFloat(bitmap[0]) / 255.0
        let g = CGFloat(bitmap[1]) / 255.0
        let b = CGFloat(bitmap[2]) / 255.0
        let a = CGFloat(bitmap[3]) / 255.0
        
        return UIColor(red: r, green: g, blue: b, alpha: a)
    }
}

extension UIImage {
    func fixedOrientation() -> UIImage {
        // å¦‚æœæ–¹å‘å·²ç»æ­£ç¡®ï¼Œç›´æ¥è¿”å›
        if imageOrientation == .up {
            return self
        }
        
        // é‡æ–°ç»˜åˆ¶å›¾ç‰‡
        UIGraphicsBeginImageContextWithOptions(size, false, scale)
        defer { UIGraphicsEndImageContext() }
        
        draw(in: CGRect(origin: .zero, size: size))
        
        return UIGraphicsGetImageFromCurrentImageContext() ?? self
    }
}
