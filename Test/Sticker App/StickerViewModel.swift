//
//  StickerViewModel.swift
//  Test
//
//  Created by è´¾å»ºè¾‰ on 2025/10/5.
//

import SwiftUI
import PhotosUI
import Vision
import CoreImage

// MARK: - å¤„ç†çŠ¶æ€æšä¸¾ï¼ˆçŠ¶æ€æœºï¼‰
enum ProcessingState {
    case initial      // åˆå§‹çŠ¶æ€
    case analyzing    // è¯†åˆ«ä¸­ï¼ˆå…¨å±æ˜¾ç¤ºåŸå›¾ï¼‰
    case extracting   // ä¸»ä½“è·³å‡ºåŠ¨ç”»
    case completed    // å®Œæˆï¼ˆæ˜¾ç¤ºå¡ç‰‡ï¼‰
}


// MARK: - vm

@MainActor
class StickerViewModel: ObservableObject {
    // ===== çŠ¶æ€ç®¡ç† =====
    @Published var currentState: ProcessingState = .initial
    
    // ===== æ•°æ®ï¼Œé€‰æ‹©çš„å›¾ç‰‡ã€è¯†åˆ«çš„ä¸»ä½“å›¾ç‰‡ï¼ˆå¸¦ç™½è‰²æè¾¹ï¼‰ =====
    @Published var capturedImage: UIImage?
    @Published var extractedSubject: UIImage?
    @Published var dominantColor: Color = .blue

    
    // ===== UI å¼¹çª—æ§åˆ¶ =====
    @Published var showPhotoPicker = false
    @Published var showSaveAlert = false
    
    // ===== è®¡ç®—å±æ€§ï¼Œå½“é€‰æ‹©ä¸€ä¸ªå›¾ç‰‡åï¼Œè‡ªåŠ¨è°ƒç”¨å‡½æ•° loadPhoto =====
    @Published var selectedPhoto: PhotosPickerItem? {
        didSet {
            if selectedPhoto != nil {
                loadPhoto()
            }
        }
    }
    
    // ===== æµç¨‹1: åŠ è½½ç…§ç‰‡ =====
    private func loadPhoto() {
        
        // ç”¨æˆ·æ²¡æœ‰é€‰æ‹©å›¾ç‰‡ï¼Œç›´æ¥è¿”å›
        guard let item = selectedPhoto else { return }
        
        
        // å¼‚æ­¥æ–¹å¼åŠ è½½å›¾ç‰‡
        Task {
            do {
                
                // è·å–å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®ï¼›
                guard let data = try await item.loadTransferable(type: Data.self),
                      // æŠŠäºŒè¿›åˆ¶æ•°æ®è½¬æ¢æˆå›¾ç‰‡
                      let image = UIImage(data: data)
                else { return }
                
                // ä¿®æ­£å›¾ç‰‡æ–¹å‘
                let fixedImage = image.fixedOrientation()
                capturedImage = fixedImage
                
                // ã€åŠ¨ç”»é˜¶æ®µ1ã€‘åˆ‡æ¢åˆ°è¯†åˆ«çŠ¶æ€
                withAnimation(.easeIn(duration: 0.3)) {
                    currentState = .analyzing
                }
                
                // å¼€å§‹è¯†åˆ«ï¼ˆæ¨¡æ‹Ÿå»¶è¿Ÿä»¥å±•ç¤ºåŠ¨ç”»ï¼‰
                try await Task.sleep(nanoseconds: 1_500_000_000) // 1.5ç§’
                
                // æ‰§è¡Œå®é™…è¯†åˆ«
                await performExtraction(fixedImage)
                
            } catch {
                print("âŒ é”™è¯¯: \(error)")
            }
        }
    }
    
    // ===== æµç¨‹2: æ‰§è¡Œæå– =====
    private func performExtraction(_ image: UIImage) async {
        // Vision æå–ä¸»ä½“
        guard let extracted = await extractSubject(from: image) else {
            reset()
            return
        }
        
        // æ·»åŠ ç™½è¾¹
        let withBorder = addWhiteBorder(to: extracted, borderWidth: 10)
        extractedSubject = withBorder
        
        // ã€åŠ¨ç”»é˜¶æ®µ2ã€‘åˆ‡æ¢åˆ°è·³å‡ºåŠ¨ç”»
        withAnimation(.easeOut(duration: 0.3)) {
            currentState = .extracting
        }
        
        // ğŸ¨ æå–ä¸»è‰²
        dominantColor = extractDominantColor(from: image)

        
        // ç­‰å¾…è·³å‡ºåŠ¨ç”»å®Œæˆ
        try? await Task.sleep(nanoseconds: 1_600_000_000) // 1.6ç§’
        
        // ã€åŠ¨ç”»é˜¶æ®µ3ã€‘åˆ‡æ¢åˆ°å®ŒæˆçŠ¶æ€
        withAnimation(.spring(response: 0.6, dampingFraction: 0.8)) {
            currentState = .completed
        }
    }
    
    // ===== Vision AI æå–ä¸»ä½“ =====
    private func extractSubject(from image: UIImage) async -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        
        do {
            let request = VNGenerateForegroundInstanceMaskRequest()
            let handler = VNImageRequestHandler(cgImage: cgImage)
            try handler.perform([request])
            
            guard let result = request.results?.first else { return nil }
            
            let mask = try result.generateScaledMaskForImage(
                forInstances: result.allInstances,
                from: handler
            )
            
            return applyMask(mask, to: image)
            
        } catch {
            print("âŒ Vision é”™è¯¯: \(error)")
            return nil
        }
    }
    
    // ===== åº”ç”¨è’™ç‰ˆ =====
    private func applyMask(_ mask: CVPixelBuffer, to image: UIImage) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        
        let ciImage = CIImage(cgImage: cgImage)
        let maskCIImage = CIImage(cvPixelBuffer: mask)
        
        let scaleX = ciImage.extent.width / maskCIImage.extent.width
        let scaleY = ciImage.extent.height / maskCIImage.extent.height
        let scaledMask = maskCIImage.transformed(by: CGAffineTransform(scaleX: scaleX, y: scaleY))
        
        guard let filter = CIFilter(name: "CIBlendWithMask") else { return nil }
        filter.setValue(ciImage, forKey: kCIInputImageKey)
        filter.setValue(scaledMask, forKey: kCIInputMaskImageKey)
        filter.setValue(CIImage.empty(), forKey: kCIInputBackgroundImageKey)
        
        guard let output = filter.outputImage else { return nil }
        
        let context = CIContext()
        guard let cgOutput = context.createCGImage(output, from: output.extent) else { return nil }
        
        return UIImage(cgImage: cgOutput)
    }
    
    // ===== æ·»åŠ ç™½è¾¹ =====
    private func addWhiteBorder(to image: UIImage, borderWidth: CGFloat) -> UIImage {
        let newSize = CGSize(
            width: image.size.width + borderWidth * 2,
            height: image.size.height + borderWidth * 2
        )
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        guard let context = UIGraphicsGetCurrentContext() else { return image }
        
        context.setFillColor(UIColor.clear.cgColor)
        context.fill(CGRect(origin: .zero, size: newSize))
        
        image.draw(in: CGRect(
            x: borderWidth,
            y: borderWidth,
            width: image.size.width,
            height: image.size.height
        ))
        
        return UIGraphicsGetImageFromCurrentImageContext() ?? image
    }
    
    
    // æå–ä¸»è‰²
    private func extractDominantColor(from image: UIImage, brightnessFactor: CGFloat = 1.6) -> Color {
        guard let cgImage = image.cgImage else { return .gray }
        
        let size = CGSize(width: 1, height: 1) // ç¼©å°ä¸º 1x1 å›¾åƒå–å¹³å‡è‰²
        UIGraphicsBeginImageContext(size)
        guard let context = UIGraphicsGetCurrentContext() else { return .gray }
        
        context.interpolationQuality = .medium
        context.draw(cgImage, in: CGRect(origin: .zero, size: size))
        
        guard let pixelData = context.data else {
            UIGraphicsEndImageContext()
            return .gray
        }
        
        let data = pixelData.bindMemory(to: UInt8.self, capacity: 4)
        var r = CGFloat(data[2]) / 255.0
        var g = CGFloat(data[1]) / 255.0
        var b = CGFloat(data[0]) / 255.0
        
        UIGraphicsEndImageContext()
        
        // æå‡äº®åº¦
        r = min(r * brightnessFactor, 1.0)
        g = min(g * brightnessFactor, 1.0)
        b = min(b * brightnessFactor, 1.0)
        
        return Color(red: r, green: g, blue: b)
    }


    
    // ===== ä¿å­˜ =====
    func saveSticker() {
        guard let image = extractedSubject else { return }
        UIImageWriteToSavedPhotosAlbum(image, nil, nil, nil)
        showSaveAlert = true
    }
    
    // ===== é‡ç½® =====
    func reset() {
        withAnimation(.easeOut(duration: 0.3)) {
            currentState = .initial
        }
        capturedImage = nil
        extractedSubject = nil
        selectedPhoto = nil
    }
}


extension UIImage {
    func fixedOrientation() -> UIImage {
        // å¦‚æœæ–¹å‘å·²ç»æ­£ç¡®ï¼Œç›´æ¥è¿”å›
        if imageOrientation == .up {
            return self
        }
        
        // é‡æ–°ç»˜åˆ¶å›¾ç‰‡
        UIGraphicsBeginImageContextWithOptions(size, false, scale)
        defer { UIGraphicsEndImageContext() }
        
        draw(in: CGRect(origin: .zero, size: size))
        
        return UIGraphicsGetImageFromCurrentImageContext() ?? self
    }
}
